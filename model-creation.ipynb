{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from glob import glob\n",
    "from fastai.vision.all import *\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load study slices and resample to a fixed number (e.g., 30)\n",
    "def load_study_slices(study_id, target_slices=30):\n",
    "    # Load the DICOM files for the given study\n",
    "    study_folder = f'rsna-2024-lumbar-spine-degenerative-classification/train_images/{study_id}'\n",
    "    dicom_files = sorted(glob(f'{study_folder}/**/*.dcm', recursive=True))\n",
    "    \n",
    "    # Load images and convert them to numpy arrays\n",
    "    slices = [pydicom.dcmread(dcm_file).pixel_array for dcm_file in dicom_files]\n",
    "    \n",
    "    # Normalize the slices to the target number of slices\n",
    "    if len(slices) < target_slices:\n",
    "        # If fewer than target, repeat slices\n",
    "        indices = np.linspace(0, len(slices)-1, target_slices, dtype=int)\n",
    "        slices = [slices[i] for i in indices]\n",
    "    elif len(slices) > target_slices:\n",
    "        # If more than target, sample evenly\n",
    "        indices = np.linspace(0, len(slices)-1, target_slices, dtype=int)\n",
    "        slices = [slices[i] for i in indices]\n",
    "    \n",
    "    # Stack slices into a 3D array (depth, height, width)\n",
    "    slices_stacked = np.stack(slices, axis=0)\n",
    "    return slices_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split data by study_id\n",
    "def study_based_splitter(df, valid_pct=0.2):\n",
    "    # Get unique study IDs\n",
    "    study_ids = df['study_id'].unique()\n",
    "    \n",
    "    # Randomly shuffle and split the study IDs\n",
    "    n_valid = int(len(study_ids) * valid_pct)\n",
    "    np.random.shuffle(study_ids)\n",
    "    \n",
    "    # Define train and validation splits\n",
    "    valid_study_ids = study_ids[:n_valid]\n",
    "    train_study_ids = study_ids[n_valid:]\n",
    "    \n",
    "    # Create train and valid masks\n",
    "    train_idx = df['study_id'].isin(train_study_ids)\n",
    "    valid_idx = df['study_id'].isin(valid_study_ids)\n",
    "    \n",
    "    return np.where(train_idx)[0], np.where(valid_idx)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file with the study information\n",
    "df = pd.read_csv('path_to_csv/train.csv')  # Make sure to provide the correct path to your CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DataBlock with a study-based split\n",
    "spine_block = DataBlock(\n",
    "    blocks=(ImageBlock(cls=PILImageBW), MultiCategoryBlock),\n",
    "    get_x=lambda row: load_study_slices(row['study_id'], target_slices=30),  # Fixed to 30 slices per study\n",
    "    get_y=ColReader(['normal_mild', 'moderate', 'severe']),  # Adjust the columns to your labels\n",
    "    splitter=IndexSplitter(study_based_splitter(df)),\n",
    "    item_tfms=Resize(224),  # Resize each slice to 224x224\n",
    "    batch_tfms=aug_transforms(flip_vert=True)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "dls = spine_block.dataloaders(df, bs=4)  # Adjust batch size (bs) as needed\n",
    "\n",
    "# Define a simple 3D ResNet model for this task (e.g., MedicalNet or 3D ResNet)\n",
    "def get_pretrained_resnet3d(num_classes):\n",
    "    # Placeholder for 3D ResNet loading, assuming you have a model with pretrained weights\n",
    "    # You can use a model like MedicalNet's ResNet (or any custom 3D CNN) and adjust accordingly\n",
    "    # Return a model with the number of output classes for multi-label classification\n",
    "    pass\n",
    "\n",
    "model = get_pretrained_resnet3d(num_classes=3)\n",
    "\n",
    "# FastAI Learner\n",
    "learn = Learner(dls, model, metrics=accuracy_multi)\n",
    "\n",
    "# Fine-tune the pre-trained model\n",
    "learn.fine_tune(3, base_lr=1e-3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
